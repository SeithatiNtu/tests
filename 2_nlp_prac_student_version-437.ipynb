{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Practical Test Model Answer\n",
    "----\n",
    "\n",
    "The NLP practical test will take place within this Jupyter notebook. Each question will require you to write a function which will return the answer. This notebook will be graded automatically, so it is important that the names of any existing variables and functions are left unchanged.\n",
    "\n",
    "A shell function with the correct name for each question has already been defined for you. You will simply need to fill in the necessary code inside the function, as directed by the comments.\n",
    "\n",
    "Each function has a return statement that reads `return none` - you will need to replace `none` with the relevant variable name that you specify in the function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Libraries and Read In the Data\n",
    "\n",
    "Do not modify or remove any of the code in these cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\phomolo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\phomolo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import TreebankWordTokenizer, SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alice's Adventures in Wonderland\n",
      "\n",
      "                ALICE'S ADVENTURES IN WONDERLAND\n",
      "\n",
      "                          Lewis Carroll\n",
      "\n",
      "               THE MILLENNIUM FULCRUM EDITION 3.0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                            CHAPTER I\n",
      "\n",
      "                      Down the Rabbit-Hole\n",
      "\n",
      "\n",
      "  Alice was beginning to get very tired of sitting by her sister\n",
      "on the bank, and of having nothing to do:  once or twice she had\n",
      "peeped into the book her sister was reading, but it had no\n",
      "pictures or conversations in it, `and what is the use of a book,'\n",
      "thought Alice `without pictures or conversation?'\n",
      "\n",
      "  So she was considering in her own mind (as well as she could,\n",
      "for the hot day made her feel very sleepy and stupid), whether\n",
      "the pleasure of making a daisy-chain would be worth the trouble\n",
      "of getting up and picking the daisies, when suddenly a White\n",
      "Rabbit with pink eyes ran close by her.\n",
      "\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# read in the data, you can find this data attached to the test on Athena\n",
    "data = open('alice_in_wonderland.txt', 'r', encoding='ISO-8859-1').read()\n",
    "print(data[:863])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert to Lowercase and Remove Punctuation\n",
    "\n",
    "Do not modify or remove any of the code in these cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(words):\n",
    "    words = words.lower()\n",
    "    return ''.join([char for char in words if char not in string.punctuation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = remove_punctuation(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define stemmer function\n",
    "stemmer = SnowballStemmer('english')\n",
    "\n",
    "# tokenise data\n",
    "tokeniser = TreebankWordTokenizer()\n",
    "tokens = tokeniser.tokenize(data)\n",
    "\n",
    "# define lemmatiser\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# bag of words\n",
    "def bag_of_words_count(words, word_dict={}):\n",
    "    \"\"\" this function takes in a list of words and returns a dictionary \n",
    "        with each word as a key, and the value represents the number of \n",
    "        times that word appeared\"\"\"\n",
    "    for word in words:\n",
    "        if word in word_dict.keys():\n",
    "            word_dict[word] += 1\n",
    "        else:\n",
    "            word_dict[word] = 1\n",
    "    return word_dict\n",
    "\n",
    "# remove stopwords\n",
    "tokens_less_stopwords = [word for word in tokens if word not in stopwords.words('english')]\n",
    "\n",
    "# create bag of words\n",
    "bag_of_words = bag_of_words_count(tokens_less_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1: What is the 14th character in the book?\n",
    "\n",
    "Write a function which extracts the 14th character from the relevant body of text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def char_14(text):\n",
    "    return text[13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'u'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_14(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Question 2: What is the 34th word in the book?\n",
    "\n",
    "Modify the function below to return the 34th word from the relevant body of text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_34(tokens):\n",
    "    return tokens[33] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_34(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Question 3: How many words are in the book?\n",
    "\n",
    "Modify the function below to return the total number of words from the relevant body of text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_words(tokens):\n",
    "    return len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26411"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_words(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Question 4: What is the stem of the word '*writing*'\n",
    "\n",
    "Write a function which returns the stem of the word 'writing'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_stem(word):\n",
    "    return stemmer.stem(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'write'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_stem('writing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5: What is the stem of the 55th word in the book?\n",
    "\n",
    "Write a function which returns the stem of the word in position 55 in the book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_stem_n(tokens, n):\n",
    "    return stemmer.stem(tokens[n-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'but'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_stem_n(tokens, 55)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Question 6: What is the lemma of the word '*hippopotami*'?\n",
    "\n",
    "Use the lemmatizer function from the relevant library to find the lemma of the word 'hippopotami'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_lemma(word):\n",
    "    return lemmatizer.lemmatize(word) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hippopotamus'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_lemma('hippopotami')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Question 7: What is the lemma of the 389th word in the book?\n",
    "\n",
    "Modify the function below to find the lemma of the word in the 389th position in the book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_lemma_n(tokens, n):\n",
    "    return lemmatizer.lemmatize(tokens[n-1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'see'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_lemma_n(tokens, 389)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Question 8: How many stopwords are in the book?\n",
    "\n",
    "Modify the function below to count the total number of stopwords that appear in the body of text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_stopwords(tokens):\n",
    "    from collections import Counter\n",
    "    stops = stopwords.words('english')\n",
    "    count = Counter(w for w in tokens if w in stops)\n",
    "    return len(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_stopwords(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Question 9: How any times does '*Alice*' appear in the book?\n",
    "\n",
    "Modify the function below to return the count for the number of times the word 'Alice' appears in the book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_count(bag, word):\n",
    "    count = bag[word]\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "386"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count(bag_of_words, 'alice')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 10: What is the most common word in the book?\n",
    "\n",
    "Modify the function below to return the word which appears to most times in the book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_common_word(bag):\n",
    "    max_word = max(bag, key=bag.get)\n",
    "    return max_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'said'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_common_word(bag_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
